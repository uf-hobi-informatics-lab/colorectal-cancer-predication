{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import shap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_score, StratifiedKFold, cross_val_predict, train_test_split\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, roc_curve, auc, precision_recall_fscore_support\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#UTF-8 encoding issue\n",
    "\n",
    "def pkl_dump(data, file):\n",
    "    with open(file, \"wb\") as fw:\n",
    "        pkl.dump(data, fw)\n",
    "\n",
    "        \n",
    "def pkl_load(file):\n",
    "    with open(file, \"rb\") as fr:\n",
    "        data = pkl.load(fr)\n",
    "    return data\n",
    "\n",
    "def pkl4_dump(data, file):\n",
    "    with open(file, \"wb\") as fw:\n",
    "        pkl.dump(data, fw, pkl.HIGHEST_PROTOCOL)\n",
    "\n",
    "        \n",
    "def pkl4_load(file):\n",
    "    with open(file, \"rb\") as fr:\n",
    "        data = pkl.load(fr)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/data1/songziwu/data/crc_data'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('/mnt/data1/songziwu/data/crc_data/')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add performance report on training data cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expr(clf, params, tasks, nb=-1, nit=100, model_name='LR'):\n",
    "    for task in tasks:\n",
    "        print(f\"current task: {task} {model_name}\")\n",
    "        res_output = f\"{task}year_{model_name}.txt\"\n",
    "        model_dump = f\"{task}year_{model_name}_model.pkl\"\n",
    "\n",
    "        fea2iD, features = pkl_load(f\"./03_MQ_Encoding_Files/data_CC{task}yr_expr_features.pkl\")\n",
    "        tr_dx, tr_dy, ts_dx, ts_dy = pkl4_load(f\"./03_MQ_Encoding_Files/expr_data_CC{task}yr_train_test.pkl\")\n",
    "        print(tr_dx.shape, ts_dx.shape)\n",
    "        \n",
    "        cv_model = RandomizedSearchCV(clf, params, scoring='roc_auc', n_jobs=nb, \n",
    "                                      cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=13), \n",
    "                                      verbose=1, iid=True, n_iter=nit, random_state=13)\n",
    "        cv_model.fit(tr_dx, tr_dy)\n",
    "        best_5_cv = cv_model.best_estimator_\n",
    "        opt_clf = cv_model.best_estimator_\n",
    "        pkl_dump(opt_clf, model_dump)\n",
    "\n",
    "        preds = opt_clf.predict_proba(ts_dx)\n",
    "        pkl_dump(preds, f\"{task}year_{model_name}_preds.pkl\")\n",
    "\n",
    "        idx = np.argmax(opt_clf.classes_)\n",
    "        preds_1 = list(map(lambda x: x[idx], preds))\n",
    "\n",
    "        auc_score = roc_auc_score(ts_dy, preds_1)\n",
    "        fprs, tprs, ths = roc_curve(ts_dy, preds_1)\n",
    "\n",
    "        J_idx = np.argmax(tprs - fprs)\n",
    "        fpr, tpr, th = fprs[J_idx], tprs[J_idx], ths[J_idx]\n",
    "        auc_score1 = auc(fprs, tprs)\n",
    "\n",
    "        sen = tpr\n",
    "        spe = 1 - fpr\n",
    "        stats = [sen, spe, auc_score1]\n",
    "        \n",
    "# change below to shap for SVM\n",
    "\n",
    "#         shap.initjs()\n",
    "#         explainer = shap.TreeExplainer(opt_clf)\n",
    "#         shap_values = explainer.shap_values(tr_dx)\n",
    "#         top10 = shap_values[:10][:]\n",
    "        \n",
    "        with open(f\"master_{task}SVM_CCstats.csv\", \"a\") as fp:\n",
    "            wr = csv.writer(fp, dialect='excel')\n",
    "            wr.writerow(['sen','spef','auc'])\n",
    "            wr.writerow(stats)\n",
    "        \n",
    "       \n",
    "        with open(f\"master_{task}SVM_CCshap.csv\",\"a\") as sp:\n",
    "            sp = csv.writer(ir, dialect='excel')\n",
    "            sp.writerow(['feature','shap_value'])\n",
    "            sp.writerows([top10])\n",
    "            \n",
    "\n",
    "#         with open(res_output, \"w\") as f:\n",
    "#             f.write(f'''\n",
    "# auc1: {auc_score}\n",
    "# auc2: {auc_score1}\n",
    "# sensitivity: {sen}\n",
    "# specificity: {spe}\n",
    "# J: {th}\n",
    "#             ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_matrix(all_data, col_num, num_fea_cols):\n",
    "    pids = []\n",
    "    matrix = []\n",
    "    for idx, d in enumerate(all_data):\n",
    "        m = np.zeros(col_num + 1)\n",
    "        mp = []\n",
    "        if num_fea_cols == -1:\n",
    "            d1 = d\n",
    "        else:\n",
    "            d1 = d[:-num_fea_cols]\n",
    "        for i, e in enumerate(d1):\n",
    "            if i == 0:\n",
    "                m[0] = e\n",
    "            else:\n",
    "                m[e] = 1.\n",
    "        \n",
    "        if num_fea_cols == -1:\n",
    "            d2 = []\n",
    "        else:\n",
    "            d2 = d[-num_fea_cols:]\n",
    "        for e in d2:\n",
    "            mp.append(e)\n",
    "        \n",
    "        pids.append(idx)\n",
    "        nmn = np.concatenate((m, np.array(mp)))\n",
    "        matrix.append(nmn)\n",
    "    print(np.array(matrix).shape)\n",
    "    print(matrix[1])\n",
    "    return matrix, pids\n",
    "\n",
    "def imputation(matrix, pids, findings=True, labs=True):\n",
    "    cols = ['label'] + features\n",
    "    cols_to_imp = []\n",
    "    if findings:\n",
    "        cols += findings_list\n",
    "        cols_to_imp += findings_list\n",
    "    \n",
    "    if labs:\n",
    "        cols += valid_loinc\n",
    "        cols_to_imp += valid_loinc\n",
    "        \n",
    "    df = pd.DataFrame(data=matrix, index=pids, columns=cols)\n",
    "#     print(df.head())\n",
    "#     cau = dict()\n",
    "#     cou = dict()\n",
    "#     for col in cols_to_imp:\n",
    "#         cau[col] = [e for e in set(df[df['label']==1.0][col]) if not pd.isna(e)]\n",
    "#         cou[col] = [e for e in set(df[df['label']==0.0][col]) if not pd.isna(e)]\n",
    "        \n",
    "    np.random.seed(47)\n",
    "    for col in cols_to_imp:\n",
    "        s = list(set([e for e in df[col] if not np.isnan(e)]))\n",
    "        for idx, c in enumerate(df[col]):\n",
    "            if pd.isna(c):\n",
    "                # choose case or control \n",
    "#                 if df['label'][idx] == 1.0:\n",
    "#                     s = cau[col]\n",
    "#                 elif df['label'][idx] == 0.0:\n",
    "#                     s = cou[col]\n",
    "\n",
    "\n",
    "                df[col][idx] = np.random.choice(s, 1)\n",
    "                \n",
    "#     print(df.head())\n",
    "    matrix = np.array(df)\n",
    "    print(matrix.shape, matrix[0])\n",
    "    return matrix, cols[1:]\n",
    "\n",
    "def create_data(matrix):\n",
    "    np.random.seed(13)\n",
    "    np.random.shuffle(matrix)\n",
    "    np.random.seed(47)\n",
    "    np.random.shuffle(matrix)\n",
    "    dx = []\n",
    "    dy = []\n",
    "    for each in matrix:\n",
    "        dx.append(each[1:])\n",
    "        dy.append(each[0])\n",
    "    dx = np.array(dx)\n",
    "    dy = np.array(dy)\n",
    "    print(dx.shape, dy.shape)\n",
    "    return dx, dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_parameters = {\n",
    "    'max_iter': range(100, 4100, 500),\n",
    "    'tol': [0.0001, 0.001, 0.01, 0.1],\n",
    "    'C': range(1, 50, 2),\n",
    "    'class_weight': [None, 'balanced']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(probability=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 YEAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptIDs = pd.read_csv(\"01_MQ_Incident_Match_Files/matched_case_control_CC_01yr.csv\",usecols=['PATID'],dtype =str)\n",
    "ptIDs.head()\n",
    "fea2id, features = pkl_load(\"./03_MQ_Encoding_Files/data_CC0yr_expr_features.pkl\")\n",
    "data = pkl_load(\"./03_MQ_Encoding_Files/data_CC0yr_expr.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current task: 0 RF\n",
      "(5681, 10045) (1421, 10045)\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-953be8279737>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexpr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuned_parameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'RF'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-741af20c73d1>\u001b[0m in \u001b[0;36mexpr\u001b[0;34m(clf, params, tasks, nb, nit, model_name)\u001b[0m\n\u001b[1;32m     12\u001b[0m                                       \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                                       verbose=1, iid=True, n_iter=nit, random_state=13)\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mcv_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_dx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_dy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mbest_5_cv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mopt_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1482\u001b[0m         evaluate_candidates(ParameterSampler(\n\u001b[1;32m   1483\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1484\u001b[0;31m             random_state=self.random_state))\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    687\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 689\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    833\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    513\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    381\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                     n_samples_bootstrap=n_samples_bootstrap)\n\u001b[0;32m--> 383\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    833\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    875\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    878\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    365\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    train_id, test_id = train_test_split(ptIDs,test_size=0.2)\n",
    "    test_id.head(), train_id.head(), test_id.shape, train_id.shape\n",
    "    test_ids = test_id.PATID.to_list()\n",
    "    train_ids = train_id.PATID.to_list()\n",
    "\n",
    "    print(data[0][0])\n",
    "\n",
    "    trains = []\n",
    "    tests = []\n",
    "    count = 0\n",
    "    for dp in data:\n",
    "        pid = dp[0]\n",
    "        ndata = dp[1:]\n",
    "        if pid in train_ids:\n",
    "            trains.append(ndata)\n",
    "        elif pid in test_ids:\n",
    "            tests.append(ndata)\n",
    "        else:\n",
    "            count = count + 1\n",
    "\n",
    "    print(count)\n",
    "    matrix, pids = to_matrix(trains, len(fea2id), -1)\n",
    "\n",
    "    tr_dx, tr_dy = create_data(matrix)\n",
    "\n",
    "    matrix, pids = to_matrix(tests, len(fea2id), -1)\n",
    "\n",
    "    ts_dx, ts_dy = create_data(matrix)\n",
    "\n",
    "\n",
    "    pkl4_dump((tr_dx, tr_dy, ts_dx, ts_dy), \"./03_MQ_Encoding_Files/expr_data_CC0yr_train_test.pkl\")\n",
    "\n",
    "\n",
    "##Algorithm\n",
    "    expr(clf, tuned_parameters, tasks = [1], nb = 10, nit = 20, model_name = 'SVM')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 YEAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea2id, features = pkl_load(\"./03_MQ_Encoding_Files/data_CC1yr_expr_features.pkl\")\n",
    "data = pkl_load(\"./03_MQ_Encoding_Files/data_CC1yr_expr.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    train_id, test_id = train_test_split(ptIDs,test_size=0.2)\n",
    "    test_id.head(), train_id.head(), test_id.shape, train_id.shape\n",
    "    test_ids = test_id.PATID.to_list()\n",
    "    train_ids = train_id.PATID.to_list()\n",
    "\n",
    "# split train and test\n",
    "    print(data[0][0])\n",
    "#print(len(data))\n",
    "    trains = []\n",
    "    tests = []\n",
    "    count = 0\n",
    "    for dp in data:\n",
    "        pid = dp[0]\n",
    "        ndata = dp[1:]\n",
    "        if pid in train_ids:\n",
    "            trains.append(ndata)\n",
    "        elif pid in test_ids:\n",
    "            tests.append(ndata)\n",
    "        else:\n",
    "        #print(f\"{pid} is not an id in train test\")\n",
    "        count = count + 1\n",
    "# coln = len(valid_loinc) + len(findings_list)\n",
    "    print(count)\n",
    "    matrix, pids = to_matrix(trains, len(fea2id), -1)\n",
    "# matrix, feas = imputation(matrix, pids)\n",
    "    tr_dx, tr_dy = create_data(matrix)\n",
    "\n",
    "    matrix, pids = to_matrix(tests, len(fea2id), -1)\n",
    "# matrix, feas = imputation(matrix, pids)\n",
    "    ts_dx, ts_dy = create_data(matrix)\n",
    "\n",
    "# pkl_dump(feas, \"./expr_data_5yr_features.pkl\")\n",
    "    pkl4_dump((tr_dx, tr_dy, ts_dx, ts_dy), \"./03_MQ_Encoding_Files/expr_data_CC1yr_train_test.pkl\")\n",
    "# pkl4_dump((), \"./expr_data_5yr_test.pkl\")\n",
    "    \n",
    "    expr(clf, tuned_parameters, tasks = [1], nb = 10, nit = 20, model_name = 'SVM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 YEAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptIDs = pd.read_csv(\"01_MQ_Incident_Match_Files/matched_case_control_CC_3yr.csv\",usecols=['PATID'],dtype =str)\n",
    "ptIDs.head()\n",
    "fea2id, features = pkl_load(\"./03_MQ_Encoding_Files/data_CC3yr_expr_features.pkl\")\n",
    "data = pkl_load(\"./03_MQ_Encoding_Files/data_CC3yr_expr.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    train_id, test_id = train_test_split(ptIDs,test_size=0.2)\n",
    "    test_id.head(), train_id.head(), test_id.shape, train_id.shape\n",
    "    test_ids = test_id.PATID.to_list()\n",
    "    train_ids = train_id.PATID.to_list()\n",
    "\n",
    "# split train and test\n",
    "    print(data[0][0])\n",
    "#print(len(data))\n",
    "    trains = []\n",
    "    tests = []\n",
    "    count = 0\n",
    "    for dp in data:\n",
    "        pid = dp[0]\n",
    "        ndata = dp[1:]\n",
    "        if pid in train_ids:\n",
    "            trains.append(ndata)\n",
    "        elif pid in test_ids:\n",
    "            tests.append(ndata)\n",
    "        else:\n",
    "        #print(f\"{pid} is not an id in train test\")\n",
    "            count = count + 1\n",
    "# coln = len(valid_loinc) + len(findings_list)\n",
    "    print(count)\n",
    "    matrix, pids = to_matrix(trains, len(fea2id), -1)\n",
    "# matrix, feas = imputation(matrix, pids)\n",
    "    tr_dx, tr_dy = create_data(matrix)\n",
    "\n",
    "    matrix, pids = to_matrix(tests, len(fea2id), -1)\n",
    "# matrix, feas = imputation(matrix, pids)\n",
    "    ts_dx, ts_dy = create_data(matrix)\n",
    "\n",
    "# pkl_dump(feas, \"./expr_data_5yr_features.pkl\")\n",
    "    pkl4_dump((tr_dx, tr_dy, ts_dx, ts_dy), \"./03_MQ_Encoding_Files/expr_data_CC3yr_train_test.pkl\")\n",
    "# pkl4_dump((), \"./expr_data_5yr_test.pkl\")\n",
    "    expr(clf, tuned_parameters, tasks = [3], nb = 10, nit = 20, model_name = 'SVM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 YEAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptIDs = pd.read_csv(\"01_MQ_Incident_Match_Files/matched_case_control_CC_5yr.csv\",usecols=['PATID'],dtype =str)\n",
    "ptIDs.head()\n",
    "fea2id, features = pkl_load(\"./03_MQ_Encoding_Files/data_CC5yr_expr_features.pkl\")\n",
    "data = pkl_load(\"./03_MQ_Encoding_Files/data_CC5yr_expr.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    train_id, test_id = train_test_split(ptIDs,test_size=0.2)\n",
    "    test_id.head(), train_id.head(), test_id.shape, train_id.shape\n",
    "    test_ids = test_id.PATID.to_list()\n",
    "    train_ids = train_id.PATID.to_list()\n",
    "\n",
    "# split train and test\n",
    "    print(data[0][0])\n",
    "#print(len(data))\n",
    "    trains = []\n",
    "    tests = []\n",
    "    count = 0\n",
    "    for dp in data:\n",
    "        pid = dp[0]\n",
    "        ndata = dp[1:]\n",
    "        if pid in train_ids:\n",
    "            trains.append(ndata)\n",
    "        elif pid in test_ids:\n",
    "            tests.append(ndata)\n",
    "        else:\n",
    "        #print(f\"{pid} is not an id in train test\")\n",
    "            count = count + 1\n",
    "# coln = len(valid_loinc) + len(findings_list)\n",
    "    print(count)\n",
    "    matrix, pids = to_matrix(trains, len(fea2id), -1)\n",
    "# matrix, feas = imputation(matrix, pids)\n",
    "    tr_dx, tr_dy = create_data(matrix)\n",
    "\n",
    "    matrix, pids = to_matrix(tests, len(fea2id), -1)\n",
    "# matrix, feas = imputation(matrix, pids)\n",
    "    ts_dx, ts_dy = create_data(matrix)\n",
    "\n",
    "# pkl_dump(feas, \"./expr_data_5yr_features.pkl\")\n",
    "    pkl4_dump((tr_dx, tr_dy, ts_dx, ts_dy), \"./03_MQ_Encoding_Files/expr_data_CC5yr_train_test.pkl\")\n",
    "# pkl4_dump((), \"./expr_data_5yr_test.pkl\")\n",
    "    expr(clf, tuned_parameters, tasks = [5], nb = 10, nit = 20, model_name = 'SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Untuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5681, 10046)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(5681, 10045) (5681,)\n",
      "(1421, 10046)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(1421, 10045) (1421,)\n",
      "current task: 0 SVM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "\n",
      " 20%|██        | 1/5 [08:31<34:05, 511.46s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score is :  0.7248173535302248\n",
      "(5681, 10046)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(5681, 10045) (5681,)\n",
      "(1421, 10046)\n",
      "[1. 0. 0. ... 0. 0. 0.]\n",
      "(1421, 10045) (1421,)\n",
      "current task: 0 SVM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "\n",
      " 40%|████      | 2/5 [17:04<25:35, 511.84s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score is :  0.68383192352658\n",
      "(5681, 10046)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(5681, 10045) (5681,)\n",
      "(1421, 10046)\n",
      "[1. 0. 0. ... 0. 0. 0.]\n",
      "(1421, 10045) (1421,)\n",
      "current task: 0 SVM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "\n",
      " 60%|██████    | 3/5 [26:07<17:22, 521.43s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score is :  0.68383192352658\n",
      "(5681, 10046)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(5681, 10045) (5681,)\n",
      "(1421, 10046)\n",
      "[1. 0. 0. ... 0. 0. 0.]\n",
      "(1421, 10045) (1421,)\n",
      "current task: 0 SVM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "\n",
      " 80%|████████  | 4/5 [35:14<08:49, 529.09s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score is :  0.68383192352658\n",
      "(5681, 10046)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(5681, 10045) (5681,)\n",
      "(1421, 10046)\n",
      "[1. 0. 0. ... 0. 0. 0.]\n",
      "(1421, 10045) (1421,)\n",
      "current task: 0 SVM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "\n",
      "100%|██████████| 5/5 [44:25<00:00, 535.48s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score is :  0.68383192352658\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "clf = svm.SVC(probability=True)\n",
    "\n",
    "\n",
    "def expr(clf, tasks, model_name):\n",
    "\n",
    "    for task in tasks:\n",
    "        print(f\"current task: {task} {model_name}\")\n",
    "        res_output = f\"{task}year_{model_name}.txt\"\n",
    "        model_dump = f\"{task}year_{model_name}_model.pkl\"\n",
    "\n",
    "        fea2iD, features = pkl_load(f\"./03_MQ_Encoding_Files/data_CC{task}yr_expr_features.pkl\")\n",
    "        tr_dx, tr_dy, ts_dx, ts_dy = pkl4_load(f\"./03_MQ_Encoding_Files/expr_data_CC{task}yr_train_test.pkl\")\n",
    "\n",
    "        \n",
    "\n",
    "        clf.fit(tr_dx, tr_dy)\n",
    "\n",
    "        pkl_dump(clf, model_dump)\n",
    "\n",
    "        preds = clf.predict_proba(ts_dx)\n",
    "        pkl_dump(preds, f\"{task}year_{model_name}_preds.pkl\")\n",
    "\n",
    "        idx = np.argmax(clf.classes_)\n",
    "        preds_1 = list(map(lambda x: x[idx], preds))\n",
    "\n",
    "        auc_score = roc_auc_score(ts_dy, preds_1)\n",
    "        fprs, tprs, ths = roc_curve(ts_dy, preds_1)\n",
    "        print(\"auc_score is : \",auc_score)\n",
    "\n",
    "#         J_idx = np.argmax(tprs - fprs)\n",
    "#         fpr, tpr, th = fprs[J_idx], tprs[J_idx], ths[J_idx]\n",
    "#         auc_score1 = auc(fprs, tprs)\n",
    "\n",
    "        return auc_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in tqdm(range(5)):\n",
    "    train_id, test_id = train_test_split(ptIDs,test_size=0.2)\n",
    "    test_id.head(), train_id.head(), test_id.shape, train_id.shape\n",
    "    test_ids = test_id.PATID.to_list()\n",
    "    train_ids = train_id.PATID.to_list()\n",
    "\n",
    "    #print(data[0][0])\n",
    "\n",
    "    trains = []\n",
    "    tests = []\n",
    "    count = 0\n",
    "    for dp in data:\n",
    "        pid = dp[0]\n",
    "        ndata = dp[1:]\n",
    "        if pid in train_ids:\n",
    "            trains.append(ndata)\n",
    "        elif pid in test_ids:\n",
    "            tests.append(ndata)\n",
    "        else:\n",
    "            count = count + 1\n",
    "\n",
    "    #print(count)\n",
    "    matrix, pids = to_matrix(trains, len(fea2id), -1)\n",
    "\n",
    "    tr_dx, tr_dy = create_data(matrix)\n",
    "\n",
    "    matrix, pids = to_matrix(tests, len(fea2id), -1)\n",
    "\n",
    "    ts_dx, ts_dy = create_data(matrix)\n",
    "\n",
    "\n",
    "    pkl4_dump((tr_dx, tr_dy, ts_dx, ts_dy), \"./03_MQ_Encoding_Files/expr_data_CC0yr_train_test.pkl\")\n",
    "\n",
    "\n",
    "##Algorithm\n",
    "    expr(clf, tasks = [0], model_name = 'SVM')\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nit test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(5681, 10046)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(5681, 10045) (5681,)\n",
      "(1421, 10046)\n",
      "[1. 0. 0. ... 0. 0. 0.]\n",
      "(1421, 10045) (1421,)\n",
      "current task: 0 SVM\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "Solver terminated early (max_iter=600).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "Solver terminated early (max_iter=600).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "Solver terminated early (max_iter=600).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "Solver terminated early (max_iter=600).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "Solver terminated early (max_iter=600).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-a95d4198a821>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;31m##Algorithm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0mexpr1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuned_parameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'SVM'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-a95d4198a821>\u001b[0m in \u001b[0;36mexpr1\u001b[0;34m(clf, params, tasks, nb, nit, model_name)\u001b[0m\n\u001b[1;32m     13\u001b[0m                                       \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                                       verbose=1, iid=True, n_iter=nit)\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mcv_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_dx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_dy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mbest_5_cv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mopt_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1513\u001b[0m         evaluate_candidates(ParameterSampler(\n\u001b[1;32m   1514\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1515\u001b[0;31m             random_state=self.random_state))\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    709\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 711\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    269\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "clf1 = svm.SVC(probability=True)\n",
    "def expr1(clf, params, tasks, nb, nit, model_name):\n",
    "    for task in tasks:\n",
    "        print(f\"current task: {task} {model_name}\")\n",
    "        res_output = f\"{task}year_{model_name}.txt\"\n",
    "        model_dump = f\"{task}year_{model_name}_model.pkl\"\n",
    "\n",
    "        fea2iD, features = pkl_load(f\"./03_MQ_Encoding_Files/data_CC{task}yr_expr_features.pkl\")\n",
    "        tr_dx, tr_dy, ts_dx, ts_dy = pkl4_load(f\"./03_MQ_Encoding_Files/expr_data_CC{task}yr_train_test.pkl\")\n",
    "        #print(tr_dx.shape, ts_dx.shape)\n",
    "        \n",
    "        cv_model = RandomizedSearchCV(clf, params, scoring='roc_auc', n_jobs=nb, \n",
    "                                      cv=StratifiedKFold(n_splits=5, shuffle=True), \n",
    "                                      verbose=1, iid=True, n_iter=nit)\n",
    "        cv_model.fit(tr_dx, tr_dy)\n",
    "        best_5_cv = cv_model.best_estimator_\n",
    "        opt_clf = cv_model.best_estimator_\n",
    "        pkl_dump(opt_clf, model_dump)\n",
    "\n",
    "        preds = opt_clf.predict_proba(ts_dx)\n",
    "        pkl_dump(preds, f\"{task}year_{model_name}_preds.pkl\")\n",
    "\n",
    "        idx = np.argmax(opt_clf.classes_)\n",
    "        preds_1 = list(map(lambda x: x[idx], preds))\n",
    "\n",
    "        auc_score = roc_auc_score(ts_dy, preds_1)\n",
    "        fprs, tprs, ths = roc_curve(ts_dy, preds_1)\n",
    "        print(\"auc_score is : \",auc_score)\n",
    "        \n",
    "        return auc_score\n",
    "#         J_idx = np.argmax(tprs - fprs)\n",
    "#         fpr, tpr, th = fprs[J_idx], tprs[J_idx], ths[J_idx]\n",
    "#         auc_score1 = auc(fprs, tprs)\n",
    "\n",
    "#         sen = tpr\n",
    "#         spe = 1 - fpr\n",
    "#         stats = [sen, spe, auc_score1]\n",
    "        \n",
    "# change below to shap for SVM\n",
    "\n",
    "#         shap.initjs()\n",
    "#         explainer = shap.TreeExplainer(opt_clf)\n",
    "#         shap_values = explainer.shap_values(tr_dx)\n",
    "#         top10 = shap_values[:10][:]\n",
    "        \n",
    "#         with open(f\"master_{task}SVM_CCstats.csv\", \"a\") as fp:\n",
    "#             wr = csv.writer(fp, dialect='excel')\n",
    "#             wr.writerow(['sen','spef','auc'])\n",
    "#             wr.writerow(stats)\n",
    "        \n",
    "       \n",
    "#         with open(f\"master_{task}SVM_CCshap.csv\",\"a\") as sp:\n",
    "#             sp = csv.writer(ir, dialect='excel')\n",
    "#             sp.writerow(['feature','shap_value'])\n",
    "#             sp.writerows([top10])\n",
    "            \n",
    "\n",
    "#         with open(res_output, \"w\") as f:\n",
    "#             f.write(f'''\n",
    "# auc1: {auc_score}\n",
    "# auc2: {auc_score1}\n",
    "# sensitivity: {sen}\n",
    "# specificity: {spe}\n",
    "# J: {th}\n",
    "#             ''')\n",
    "\n",
    "ptIDs = pd.read_csv(\"01_MQ_Incident_Match_Files/matched_case_control_CC_01yr.csv\",usecols=['PATID'],dtype =str)\n",
    "ptIDs.head()\n",
    "fea2id, features = pkl_load(\"./03_MQ_Encoding_Files/data_CC0yr_expr_features.pkl\")\n",
    "data = pkl_load(\"./03_MQ_Encoding_Files/data_CC0yr_expr.pkl\")\n",
    "\n",
    "\n",
    "\n",
    "for i in tqdm(range(5)):\n",
    "    train_id, test_id = train_test_split(ptIDs,test_size=0.2)\n",
    "    test_id.head(), train_id.head(), test_id.shape, train_id.shape\n",
    "    test_ids = test_id.PATID.to_list()\n",
    "    train_ids = train_id.PATID.to_list()\n",
    "\n",
    "    #print(data[0][0])\n",
    "\n",
    "    trains = []\n",
    "    tests = []\n",
    "    count = 0\n",
    "    for dp in data:\n",
    "        pid = dp[0]\n",
    "        ndata = dp[1:]\n",
    "        if pid in train_ids:\n",
    "            trains.append(ndata)\n",
    "        elif pid in test_ids:\n",
    "            tests.append(ndata)\n",
    "        else:\n",
    "            count = count + 1\n",
    "\n",
    "    print(count)\n",
    "    matrix, pids = to_matrix(trains, len(fea2id), -1)\n",
    "\n",
    "    tr_dx, tr_dy = create_data(matrix)\n",
    "\n",
    "    matrix, pids = to_matrix(tests, len(fea2id), -1)\n",
    "\n",
    "    ts_dx, ts_dy = create_data(matrix)\n",
    "\n",
    "\n",
    "    pkl4_dump((tr_dx, tr_dy, ts_dx, ts_dy), \"./03_MQ_Encoding_Files/expr_data_CC0yr_train_test.pkl\")\n",
    "\n",
    "\n",
    "##Algorithm\n",
    "    expr1(clf1, tuned_parameters, tasks = [0], nb = 1, nit = 20, model_name = 'SVM')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(5681, 10046)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(5681, 10045) (5681,)\n",
      "(1421, 10046)\n",
      "[1. 0. 0. ... 0. 0. 0.]\n",
      "(1421, 10045) (1421,)\n",
      "current task: 0 SVM\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed: 75.4min\n",
      "[Parallel(n_jobs=10)]: Done  50 out of  50 | elapsed: 100.7min finished\n",
      "The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "\n",
      " 20%|██        | 1/5 [1:48:12<7:12:51, 6492.79s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score is :  0.6818100543291383\n",
      "0\n",
      "(5681, 10046)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(5681, 10045) (5681,)\n",
      "(1421, 10046)\n",
      "[1. 0. 0. ... 0. 0. 0.]\n",
      "(1421, 10045) (1421,)\n",
      "current task: 0 SVM\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed: 77.1min\n",
      "[Parallel(n_jobs=10)]: Done  50 out of  50 | elapsed: 103.8min finished\n",
      "The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "Solver terminated early (max_iter=3100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "\n",
      " 40%|████      | 2/5 [3:49:54<5:36:46, 6735.53s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score is :  0.7328427077857602\n",
      "0\n",
      "(5681, 10046)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(5681, 10045) (5681,)\n",
      "(1421, 10046)\n",
      "[1. 0. 0. ... 0. 0. 0.]\n",
      "(1421, 10045) (1421,)\n",
      "current task: 0 SVM\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed: 75.7min\n",
      "[Parallel(n_jobs=10)]: Done  50 out of  50 | elapsed: 100.0min finished\n",
      "The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "Solver terminated early (max_iter=3100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "\n",
      " 60%|██████    | 3/5 [5:47:22<3:47:38, 6829.35s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score is :  0.6501500150015\n",
      "0\n",
      "(5681, 10046)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(5681, 10045) (5681,)\n",
      "(1421, 10046)\n",
      "[1. 0. 0. ... 0. 0. 0.]\n",
      "(1421, 10045) (1421,)\n",
      "current task: 0 SVM\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed: 76.5min\n",
      "[Parallel(n_jobs=10)]: Done  50 out of  50 | elapsed: 103.2min finished\n",
      "The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "Solver terminated early (max_iter=3100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "\n",
      " 80%|████████  | 4/5 [7:47:53<1:55:49, 6949.77s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score is :  0.6501500150015\n",
      "0\n",
      "(5681, 10046)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(5681, 10045) (5681,)\n",
      "(1421, 10046)\n",
      "[1. 0. 0. ... 0. 0. 0.]\n",
      "(1421, 10045) (1421,)\n",
      "current task: 0 SVM\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed: 76.4min\n",
      "[Parallel(n_jobs=10)]: Done  50 out of  50 | elapsed: 102.6min finished\n",
      "The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "Solver terminated early (max_iter=3100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "\n",
      "100%|██████████| 5/5 [9:49:03<00:00, 7045.92s/it]  \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score is :  0.6501500150015\n"
     ]
    }
   ],
   "source": [
    "clf2 = svm.SVC(probability=True)\n",
    "def expr2(clf, params, tasks, nb, nit, model_name):\n",
    "    for task in tasks:\n",
    "        print(f\"current task: {task} {model_name}\")\n",
    "        res_output = f\"{task}year_{model_name}.txt\"\n",
    "        model_dump = f\"{task}year_{model_name}_model.pkl\"\n",
    "\n",
    "        fea2iD, features = pkl_load(f\"./03_MQ_Encoding_Files/data_CC{task}yr_expr_features.pkl\")\n",
    "        tr_dx, tr_dy, ts_dx, ts_dy = pkl4_load(f\"./03_MQ_Encoding_Files/expr_data_CC{task}yr_train_test.pkl\")\n",
    "        #print(tr_dx.shape, ts_dx.shape)\n",
    "        \n",
    "        cv_model = RandomizedSearchCV(clf, params, scoring='roc_auc', n_jobs=nb, \n",
    "                                      cv=StratifiedKFold(n_splits=5, shuffle=True), \n",
    "                                      verbose=1, iid=True, n_iter=nit)\n",
    "        cv_model.fit(tr_dx, tr_dy)\n",
    "        best_5_cv = cv_model.best_estimator_\n",
    "        opt_clf = cv_model.best_estimator_\n",
    "        pkl_dump(opt_clf, model_dump)\n",
    "\n",
    "        preds = opt_clf.predict_proba(ts_dx)\n",
    "        pkl_dump(preds, f\"{task}year_{model_name}_preds.pkl\")\n",
    "\n",
    "        idx = np.argmax(opt_clf.classes_)\n",
    "        preds_1 = list(map(lambda x: x[idx], preds))\n",
    "\n",
    "        auc_score = roc_auc_score(ts_dy, preds_1)\n",
    "        fprs, tprs, ths = roc_curve(ts_dy, preds_1)\n",
    "        print(\"auc_score is : \",auc_score)\n",
    "        \n",
    "        return auc_score\n",
    "#         J_idx = np.argmax(tprs - fprs)\n",
    "#         fpr, tpr, th = fprs[J_idx], tprs[J_idx], ths[J_idx]\n",
    "#         auc_score1 = auc(fprs, tprs)\n",
    "\n",
    "#         sen = tpr\n",
    "#         spe = 1 - fpr\n",
    "#         stats = [sen, spe, auc_score1]\n",
    "        \n",
    "# change below to shap for SVM\n",
    "\n",
    "#         shap.initjs()\n",
    "#         explainer = shap.TreeExplainer(opt_clf)\n",
    "#         shap_values = explainer.shap_values(tr_dx)\n",
    "#         top10 = shap_values[:10][:]\n",
    "        \n",
    "#         with open(f\"master_{task}SVM_CCstats.csv\", \"a\") as fp:\n",
    "#             wr = csv.writer(fp, dialect='excel')\n",
    "#             wr.writerow(['sen','spef','auc'])\n",
    "#             wr.writerow(stats)\n",
    "        \n",
    "       \n",
    "#         with open(f\"master_{task}SVM_CCshap.csv\",\"a\") as sp:\n",
    "#             sp = csv.writer(ir, dialect='excel')\n",
    "#             sp.writerow(['feature','shap_value'])\n",
    "#             sp.writerows([top10])\n",
    "            \n",
    "\n",
    "#         with open(res_output, \"w\") as f:\n",
    "#             f.write(f'''\n",
    "# auc1: {auc_score}\n",
    "# auc2: {auc_score1}\n",
    "# sensitivity: {sen}\n",
    "# specificity: {spe}\n",
    "# J: {th}\n",
    "#             ''')\n",
    "\n",
    "ptIDs = pd.read_csv(\"01_MQ_Incident_Match_Files/matched_case_control_CC_01yr.csv\",usecols=['PATID'],dtype =str)\n",
    "ptIDs.head()\n",
    "fea2id, features = pkl_load(\"./03_MQ_Encoding_Files/data_CC0yr_expr_features.pkl\")\n",
    "data = pkl_load(\"./03_MQ_Encoding_Files/data_CC0yr_expr.pkl\")\n",
    "\n",
    "\n",
    "\n",
    "for i in tqdm(range(5)):\n",
    "    train_id, test_id = train_test_split(ptIDs,test_size=0.2)\n",
    "    test_id.head(), train_id.head(), test_id.shape, train_id.shape\n",
    "    test_ids = test_id.PATID.to_list()\n",
    "    train_ids = train_id.PATID.to_list()\n",
    "\n",
    "    #print(data[0][0])\n",
    "\n",
    "    trains = []\n",
    "    tests = []\n",
    "    count = 0\n",
    "    for dp in data:\n",
    "        pid = dp[0]\n",
    "        ndata = dp[1:]\n",
    "        if pid in train_ids:\n",
    "            trains.append(ndata)\n",
    "        elif pid in test_ids:\n",
    "            tests.append(ndata)\n",
    "        else:\n",
    "            count = count + 1\n",
    "\n",
    "    print(count)\n",
    "    matrix, pids = to_matrix(trains, len(fea2id), -1)\n",
    "\n",
    "    tr_dx, tr_dy = create_data(matrix)\n",
    "\n",
    "    matrix, pids = to_matrix(tests, len(fea2id), -1)\n",
    "\n",
    "    ts_dx, ts_dy = create_data(matrix)\n",
    "\n",
    "\n",
    "    pkl4_dump((tr_dx, tr_dy, ts_dx, ts_dy), \"./03_MQ_Encoding_Files/expr_data_CC0yr_train_test.pkl\")\n",
    "\n",
    "\n",
    "##Algorithm\n",
    "    expr2(clf2, tuned_parameters, tasks = [0], nb = 10, nit = 10, model_name = 'SVM')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter test - max_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_parameters_max_iter1 = {\n",
    "    #'max_iter': range(100, 4100, 500),\n",
    "    'tol': [0.0001, 0.001, 0.01, 0.1],\n",
    "    'C': range(1, 50, 2),\n",
    "    'class_weight': [None, 'balanced']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(5681, 10046)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(5681, 10045) (5681,)\n",
      "(1421, 10046)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(1421, 10045) (1421,)\n",
      "current task: 0 SVM\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed: 53.3min\n",
      "[Parallel(n_jobs=10)]: Done 100 out of 100 | elapsed: 224.9min finished\n",
      "The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [4:07:34<16:30:16, 14854.19s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score is :  0.7669158572519917\n",
      "0\n",
      "(5681, 10046)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(5681, 10045) (5681,)\n",
      "(1421, 10046)\n",
      "[1. 0. 0. ... 0. 0. 0.]\n",
      "(1421, 10045) (1421,)\n",
      "current task: 0 SVM\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed: 52.9min\n",
      "[Parallel(n_jobs=10)]: Done 100 out of 100 | elapsed: 220.4min finished\n",
      "The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [8:10:31<12:18:33, 14771.06s/it]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score is :  0.7221658412492219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <Finalize object, dead>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wusongzi/anaconda3/lib/python3.7/multiprocessing/util.py\", line 189, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/wusongzi/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/backend/synchronize.py\", line 96, in _cleanup\n",
      "    sem_unlink(name)\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n",
      "Exception ignored in: <Finalize object, dead>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wusongzi/anaconda3/lib/python3.7/multiprocessing/util.py\", line 189, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/wusongzi/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/backend/synchronize.py\", line 96, in _cleanup\n",
      "    sem_unlink(name)\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n",
      "Exception ignored in: <Finalize object, dead>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wusongzi/anaconda3/lib/python3.7/multiprocessing/util.py\", line 189, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/wusongzi/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/backend/synchronize.py\", line 96, in _cleanup\n",
      "    sem_unlink(name)\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n",
      "Exception ignored in: <Finalize object, dead>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wusongzi/anaconda3/lib/python3.7/multiprocessing/util.py\", line 189, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/wusongzi/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/backend/synchronize.py\", line 96, in _cleanup\n",
      "    sem_unlink(name)\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n",
      "Exception ignored in: <Finalize object, dead>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wusongzi/anaconda3/lib/python3.7/multiprocessing/util.py\", line 189, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/wusongzi/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/backend/synchronize.py\", line 96, in _cleanup\n",
      "    sem_unlink(name)\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n",
      "Exception ignored in: <Finalize object, dead>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wusongzi/anaconda3/lib/python3.7/multiprocessing/util.py\", line 189, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/wusongzi/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/backend/synchronize.py\", line 96, in _cleanup\n",
      "    sem_unlink(name)\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n",
      "Exception ignored in: <Finalize object, dead>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wusongzi/anaconda3/lib/python3.7/multiprocessing/util.py\", line 189, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/wusongzi/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/externals/loky/backend/synchronize.py\", line 96, in _cleanup\n",
      "    sem_unlink(name)\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(5681, 10046)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(5681, 10045) (5681,)\n",
      "(1421, 10046)\n",
      "[1. 0. 0. ... 0. 0. 0.]\n",
      "(1421, 10045) (1421,)\n",
      "current task: 0 SVM\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed: 53.0min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-c510c25796af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;31m##Algorithm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0mexpr1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuned_parameters_max_iter1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'SVM'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-c510c25796af>\u001b[0m in \u001b[0;36mexpr1\u001b[0;34m(clf, params, tasks, nb, nit, model_name)\u001b[0m\n\u001b[1;32m     13\u001b[0m                                       \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                                       verbose=1, iid=True, n_iter=nit)\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mcv_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_dx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_dy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mbest_5_cv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mopt_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1513\u001b[0m         evaluate_candidates(ParameterSampler(\n\u001b[1;32m   1514\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1515\u001b[0;31m             random_state=self.random_state))\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    709\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 711\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "clf1 = svm.SVC(probability=True)\n",
    "def expr1(clf, params, tasks, nb, nit, model_name):\n",
    "    for task in tasks:\n",
    "        print(f\"current task: {task} {model_name}\")\n",
    "        res_output = f\"{task}year_{model_name}.txt\"\n",
    "        model_dump = f\"{task}year_{model_name}_model.pkl\"\n",
    "\n",
    "        fea2iD, features = pkl_load(f\"./03_MQ_Encoding_Files/data_CC{task}yr_expr_features.pkl\")\n",
    "        tr_dx, tr_dy, ts_dx, ts_dy = pkl4_load(f\"./03_MQ_Encoding_Files/expr_data_CC{task}yr_train_test.pkl\")\n",
    "        #print(tr_dx.shape, ts_dx.shape)\n",
    "        \n",
    "        cv_model = RandomizedSearchCV(clf, params, scoring='roc_auc', n_jobs=nb, \n",
    "                                      cv=StratifiedKFold(n_splits=5, shuffle=True), \n",
    "                                      verbose=1, iid=True, n_iter=nit)\n",
    "        cv_model.fit(tr_dx, tr_dy)\n",
    "        best_5_cv = cv_model.best_estimator_\n",
    "        opt_clf = cv_model.best_estimator_\n",
    "        pkl_dump(opt_clf, model_dump)\n",
    "\n",
    "        preds = opt_clf.predict_proba(ts_dx)\n",
    "        pkl_dump(preds, f\"{task}year_{model_name}_preds.pkl\")\n",
    "\n",
    "        idx = np.argmax(opt_clf.classes_)\n",
    "        preds_1 = list(map(lambda x: x[idx], preds))\n",
    "\n",
    "        auc_score = roc_auc_score(ts_dy, preds_1)\n",
    "        fprs, tprs, ths = roc_curve(ts_dy, preds_1)\n",
    "        print(\"auc_score is : \",auc_score)\n",
    "        \n",
    "        return auc_score\n",
    "#         J_idx = np.argmax(tprs - fprs)\n",
    "#         fpr, tpr, th = fprs[J_idx], tprs[J_idx], ths[J_idx]\n",
    "#         auc_score1 = auc(fprs, tprs)\n",
    "\n",
    "#         sen = tpr\n",
    "#         spe = 1 - fpr\n",
    "#         stats = [sen, spe, auc_score1]\n",
    "        \n",
    "# change below to shap for SVM\n",
    "\n",
    "#         shap.initjs()\n",
    "#         explainer = shap.TreeExplainer(opt_clf)\n",
    "#         shap_values = explainer.shap_values(tr_dx)\n",
    "#         top10 = shap_values[:10][:]\n",
    "        \n",
    "#         with open(f\"master_{task}SVM_CCstats.csv\", \"a\") as fp:\n",
    "#             wr = csv.writer(fp, dialect='excel')\n",
    "#             wr.writerow(['sen','spef','auc'])\n",
    "#             wr.writerow(stats)\n",
    "        \n",
    "       \n",
    "#         with open(f\"master_{task}SVM_CCshap.csv\",\"a\") as sp:\n",
    "#             sp = csv.writer(ir, dialect='excel')\n",
    "#             sp.writerow(['feature','shap_value'])\n",
    "#             sp.writerows([top10])\n",
    "            \n",
    "\n",
    "#         with open(res_output, \"w\") as f:\n",
    "#             f.write(f'''\n",
    "# auc1: {auc_score}\n",
    "# auc2: {auc_score1}\n",
    "# sensitivity: {sen}\n",
    "# specificity: {spe}\n",
    "# J: {th}\n",
    "#             ''')\n",
    "\n",
    "ptIDs = pd.read_csv(\"01_MQ_Incident_Match_Files/matched_case_control_CC_01yr.csv\",usecols=['PATID'],dtype =str)\n",
    "ptIDs.head()\n",
    "fea2id, features = pkl_load(\"./03_MQ_Encoding_Files/data_CC0yr_expr_features.pkl\")\n",
    "data = pkl_load(\"./03_MQ_Encoding_Files/data_CC0yr_expr.pkl\")\n",
    "\n",
    "\n",
    "\n",
    "for i in tqdm(range(5)):\n",
    "    train_id, test_id = train_test_split(ptIDs,test_size=0.2)\n",
    "    test_id.head(), train_id.head(), test_id.shape, train_id.shape\n",
    "    test_ids = test_id.PATID.to_list()\n",
    "    train_ids = train_id.PATID.to_list()\n",
    "\n",
    "    #print(data[0][0])\n",
    "\n",
    "    trains = []\n",
    "    tests = []\n",
    "    count = 0\n",
    "    for dp in data:\n",
    "        pid = dp[0]\n",
    "        ndata = dp[1:]\n",
    "        if pid in train_ids:\n",
    "            trains.append(ndata)\n",
    "        elif pid in test_ids:\n",
    "            tests.append(ndata)\n",
    "        else:\n",
    "            count = count + 1\n",
    "\n",
    "    print(count)\n",
    "    matrix, pids = to_matrix(trains, len(fea2id), -1)\n",
    "\n",
    "    tr_dx, tr_dy = create_data(matrix)\n",
    "\n",
    "    matrix, pids = to_matrix(tests, len(fea2id), -1)\n",
    "\n",
    "    ts_dx, ts_dy = create_data(matrix)\n",
    "\n",
    "\n",
    "    pkl4_dump((tr_dx, tr_dy, ts_dx, ts_dy), \"./03_MQ_Encoding_Files/expr_data_CC0yr_train_test.pkl\")\n",
    "\n",
    "\n",
    "##Algorithm\n",
    "    expr1(clf1, tuned_parameters_max_iter1, tasks = [0], nb = 10, nit = 20, model_name = 'SVM')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(5681, 10046)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(5681, 10045) (5681,)\n",
      "(1421, 10046)\n",
      "[1. 0. 0. ... 0. 0. 0.]\n",
      "(1421, 10045) (1421,)\n",
      "current task: 0 SVM\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed: 20.3min\n",
      "[Parallel(n_jobs=10)]: Done 100 out of 100 | elapsed: 78.5min finished\n",
      "The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "Solver terminated early (max_iter=900).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [1:25:28<5:41:52, 5128.14s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score is :  0.6983382979966123\n",
      "0\n",
      "(5681, 10046)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(5681, 10045) (5681,)\n",
      "(1421, 10046)\n",
      "[1. 1. 0. ... 0. 0. 0.]\n",
      "(1421, 10045) (1421,)\n",
      "current task: 0 SVM\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed: 20.2min\n",
      "[Parallel(n_jobs=10)]: Done 100 out of 100 | elapsed: 79.3min finished\n",
      "The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "Solver terminated early (max_iter=800).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [2:50:50<4:16:19, 5126.42s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score is :  0.6854488431268122\n",
      "0\n",
      "(5681, 10046)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(5681, 10045) (5681,)\n",
      "(1421, 10046)\n",
      "[1. 1. 0. ... 0. 0. 0.]\n",
      "(1421, 10045) (1421,)\n",
      "current task: 0 SVM\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed: 21.0min\n",
      "[Parallel(n_jobs=10)]: Done 100 out of 100 | elapsed: 82.3min finished\n",
      "The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "Solver terminated early (max_iter=900).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [4:19:59<2:53:06, 5193.15s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score is :  0.6565180915266163\n",
      "0\n",
      "(5681, 10046)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(5681, 10045) (5681,)\n",
      "(1421, 10046)\n",
      "[1. 1. 0. ... 0. 0. 0.]\n",
      "(1421, 10045) (1421,)\n",
      "current task: 0 SVM\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed: 21.3min\n",
      "[Parallel(n_jobs=10)]: Done 100 out of 100 | elapsed: 81.3min finished\n",
      "The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "Solver terminated early (max_iter=800).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "\n",
      "\n",
      "\n",
      " 80%|████████  | 4/5 [5:48:05<1:27:00, 5220.90s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score is :  0.6854488431268122\n",
      "0\n",
      "(5681, 10046)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(5681, 10045) (5681,)\n",
      "(1421, 10046)\n",
      "[1. 1. 0. ... 0. 0. 0.]\n",
      "(1421, 10045) (1421,)\n",
      "current task: 0 SVM\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-7426c65a19f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;31m##Algorithm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m     \u001b[0mexpr2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuned_parameters_max_iter2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'SVM'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-7426c65a19f9>\u001b[0m in \u001b[0;36mexpr2\u001b[0;34m(clf, params, tasks, nb, nit, model_name)\u001b[0m\n\u001b[1;32m     20\u001b[0m                                       \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                                       verbose=1, iid=True, n_iter=nit)\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mcv_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_dx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_dy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mbest_5_cv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mopt_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1513\u001b[0m         evaluate_candidates(ParameterSampler(\n\u001b[1;32m   1514\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1515\u001b[0;31m             random_state=self.random_state))\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    709\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 711\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tuned_parameters_max_iter2 = {\n",
    "    'max_iter': range(100, 1000, 100),\n",
    "    'tol': [0.0001, 0.001, 0.01, 0.1],\n",
    "    'C': range(1, 50, 2),\n",
    "    'class_weight': [None, 'balanced']\n",
    "    }\n",
    "\n",
    "clf2 = svm.SVC(probability=True)\n",
    "def expr2(clf, params, tasks, nb, nit, model_name):\n",
    "    for task in tasks:\n",
    "        print(f\"current task: {task} {model_name}\")\n",
    "        res_output = f\"{task}year_{model_name}.txt\"\n",
    "        model_dump = f\"{task}year_{model_name}_model.pkl\"\n",
    "\n",
    "        fea2iD, features = pkl_load(f\"./03_MQ_Encoding_Files/data_CC{task}yr_expr_features.pkl\")\n",
    "        tr_dx, tr_dy, ts_dx, ts_dy = pkl4_load(f\"./03_MQ_Encoding_Files/expr_data_CC{task}yr_train_test.pkl\")\n",
    "        #print(tr_dx.shape, ts_dx.shape)\n",
    "        \n",
    "        cv_model = RandomizedSearchCV(clf, params, scoring='roc_auc', n_jobs=nb, \n",
    "                                      cv=StratifiedKFold(n_splits=5, shuffle=True), \n",
    "                                      verbose=1, iid=True, n_iter=nit)\n",
    "        cv_model.fit(tr_dx, tr_dy)\n",
    "        best_5_cv = cv_model.best_estimator_\n",
    "        opt_clf = cv_model.best_estimator_\n",
    "        pkl_dump(opt_clf, model_dump)\n",
    "\n",
    "        preds = opt_clf.predict_proba(ts_dx)\n",
    "        pkl_dump(preds, f\"{task}year_{model_name}_preds.pkl\")\n",
    "\n",
    "        idx = np.argmax(opt_clf.classes_)\n",
    "        preds_1 = list(map(lambda x: x[idx], preds))\n",
    "\n",
    "        auc_score = roc_auc_score(ts_dy, preds_1)\n",
    "        fprs, tprs, ths = roc_curve(ts_dy, preds_1)\n",
    "        print(\"auc_score is : \",auc_score)\n",
    "        \n",
    "        return auc_score\n",
    "#         J_idx = np.argmax(tprs - fprs)\n",
    "#         fpr, tpr, th = fprs[J_idx], tprs[J_idx], ths[J_idx]\n",
    "#         auc_score1 = auc(fprs, tprs)\n",
    "\n",
    "#         sen = tpr\n",
    "#         spe = 1 - fpr\n",
    "#         stats = [sen, spe, auc_score1]\n",
    "        \n",
    "# change below to shap for SVM\n",
    "\n",
    "#         shap.initjs()\n",
    "#         explainer = shap.TreeExplainer(opt_clf)\n",
    "#         shap_values = explainer.shap_values(tr_dx)\n",
    "#         top10 = shap_values[:10][:]\n",
    "        \n",
    "#         with open(f\"master_{task}SVM_CCstats.csv\", \"a\") as fp:\n",
    "#             wr = csv.writer(fp, dialect='excel')\n",
    "#             wr.writerow(['sen','spef','auc'])\n",
    "#             wr.writerow(stats)\n",
    "        \n",
    "       \n",
    "#         with open(f\"master_{task}SVM_CCshap.csv\",\"a\") as sp:\n",
    "#             sp = csv.writer(ir, dialect='excel')\n",
    "#             sp.writerow(['feature','shap_value'])\n",
    "#             sp.writerows([top10])\n",
    "            \n",
    "\n",
    "#         with open(res_output, \"w\") as f:\n",
    "#             f.write(f'''\n",
    "# auc1: {auc_score}\n",
    "# auc2: {auc_score1}\n",
    "# sensitivity: {sen}\n",
    "# specificity: {spe}\n",
    "# J: {th}\n",
    "#             ''')\n",
    "\n",
    "ptIDs = pd.read_csv(\"01_MQ_Incident_Match_Files/matched_case_control_CC_01yr.csv\",usecols=['PATID'],dtype =str)\n",
    "ptIDs.head()\n",
    "fea2id, features = pkl_load(\"./03_MQ_Encoding_Files/data_CC0yr_expr_features.pkl\")\n",
    "data = pkl_load(\"./03_MQ_Encoding_Files/data_CC0yr_expr.pkl\")\n",
    "\n",
    "\n",
    "\n",
    "for i in tqdm(range(5)):\n",
    "    train_id, test_id = train_test_split(ptIDs,test_size=0.2)\n",
    "    test_id.head(), train_id.head(), test_id.shape, train_id.shape\n",
    "    test_ids = test_id.PATID.to_list()\n",
    "    train_ids = train_id.PATID.to_list()\n",
    "\n",
    "    #print(data[0][0])\n",
    "\n",
    "    trains = []\n",
    "    tests = []\n",
    "    count = 0\n",
    "    for dp in data:\n",
    "        pid = dp[0]\n",
    "        ndata = dp[1:]\n",
    "        if pid in train_ids:\n",
    "            trains.append(ndata)\n",
    "        elif pid in test_ids:\n",
    "            tests.append(ndata)\n",
    "        else:\n",
    "            count = count + 1\n",
    "\n",
    "    print(count)\n",
    "    matrix, pids = to_matrix(trains, len(fea2id), -1)\n",
    "\n",
    "    tr_dx, tr_dy = create_data(matrix)\n",
    "\n",
    "    matrix, pids = to_matrix(tests, len(fea2id), -1)\n",
    "\n",
    "    ts_dx, ts_dy = create_data(matrix)\n",
    "\n",
    "\n",
    "    pkl4_dump((tr_dx, tr_dy, ts_dx, ts_dy), \"./03_MQ_Encoding_Files/expr_data_CC0yr_train_test.pkl\")\n",
    "\n",
    "\n",
    "##Algorithm\n",
    "    expr2(clf2, tuned_parameters_max_iter2, tasks = [0], nb = 10, nit = 20, model_name = 'SVM')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(5681, 10046)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(5681, 10045) (5681,)\n",
      "(1421, 10046)\n",
      "[1. 0. 0. ... 0. 0. 0.]\n",
      "(1421, 10045) (1421,)\n",
      "current task: 0 SVM\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed: 16.6min\n",
      "[Parallel(n_jobs=10)]: Done 100 out of 100 | elapsed: 54.2min finished\n",
      "The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "Solver terminated early (max_iter=450).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [58:47<3:55:08, 3527.23s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score is :  0.6683773792669498\n",
      "0\n",
      "(5681, 10046)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(5681, 10045) (5681,)\n",
      "(1421, 10046)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(1421, 10045) (1421,)\n",
      "current task: 0 SVM\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed: 16.3min\n",
      "[Parallel(n_jobs=10)]: Done 100 out of 100 | elapsed: 54.7min finished\n",
      "The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "Solver terminated early (max_iter=450).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [1:58:22<2:57:04, 3541.59s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score is :  0.7124256970179322\n",
      "0\n",
      "(5681, 10046)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(5681, 10045) (5681,)\n",
      "(1421, 10046)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(1421, 10045) (1421,)\n",
      "current task: 0 SVM\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed: 17.2min\n",
      "[Parallel(n_jobs=10)]: Done 100 out of 100 | elapsed: 58.4min finished\n",
      "The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "Solver terminated early (max_iter=400).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [3:00:52<2:00:08, 3604.02s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score is :  0.6908960470621995\n",
      "0\n",
      "(5681, 10046)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(5681, 10045) (5681,)\n",
      "(1421, 10046)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(1421, 10045) (1421,)\n",
      "current task: 0 SVM\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "tuned_parameters_max_iter3 = {\n",
    "    'max_iter': range(100, 500, 50),\n",
    "    'tol': [0.0001, 0.001, 0.01, 0.1],\n",
    "    'C': range(1, 50, 2),\n",
    "    'class_weight': [None, 'balanced']\n",
    "    }\n",
    "\n",
    "clf3 = svm.SVC(probability=True)\n",
    "def expr3(clf, params, tasks, nb, nit, model_name):\n",
    "    for task in tasks:\n",
    "        print(f\"current task: {task} {model_name}\")\n",
    "        res_output = f\"{task}year_{model_name}.txt\"\n",
    "        model_dump = f\"{task}year_{model_name}_model.pkl\"\n",
    "\n",
    "        fea2iD, features = pkl_load(f\"./03_MQ_Encoding_Files/data_CC{task}yr_expr_features.pkl\")\n",
    "        tr_dx, tr_dy, ts_dx, ts_dy = pkl4_load(f\"./03_MQ_Encoding_Files/expr_data_CC{task}yr_train_test.pkl\")\n",
    "        #print(tr_dx.shape, ts_dx.shape)\n",
    "        \n",
    "        cv_model = RandomizedSearchCV(clf, params, scoring='roc_auc', n_jobs=nb, \n",
    "                                      cv=StratifiedKFold(n_splits=5, shuffle=True), \n",
    "                                      verbose=1, iid=True, n_iter=nit)\n",
    "        cv_model.fit(tr_dx, tr_dy)\n",
    "        best_5_cv = cv_model.best_estimator_\n",
    "        opt_clf = cv_model.best_estimator_\n",
    "        pkl_dump(opt_clf, model_dump)\n",
    "\n",
    "        preds = opt_clf.predict_proba(ts_dx)\n",
    "        pkl_dump(preds, f\"{task}year_{model_name}_preds.pkl\")\n",
    "\n",
    "        idx = np.argmax(opt_clf.classes_)\n",
    "        preds_1 = list(map(lambda x: x[idx], preds))\n",
    "\n",
    "        auc_score = roc_auc_score(ts_dy, preds_1)\n",
    "        fprs, tprs, ths = roc_curve(ts_dy, preds_1)\n",
    "        print(\"auc_score is : \",auc_score)\n",
    "        \n",
    "        return auc_score\n",
    "#         J_idx = np.argmax(tprs - fprs)\n",
    "#         fpr, tpr, th = fprs[J_idx], tprs[J_idx], ths[J_idx]\n",
    "#         auc_score1 = auc(fprs, tprs)\n",
    "\n",
    "#         sen = tpr\n",
    "#         spe = 1 - fpr\n",
    "#         stats = [sen, spe, auc_score1]\n",
    "        \n",
    "# change below to shap for SVM\n",
    "\n",
    "#         shap.initjs()\n",
    "#         explainer = shap.TreeExplainer(opt_clf)\n",
    "#         shap_values = explainer.shap_values(tr_dx)\n",
    "#         top10 = shap_values[:10][:]\n",
    "        \n",
    "#         with open(f\"master_{task}SVM_CCstats.csv\", \"a\") as fp:\n",
    "#             wr = csv.writer(fp, dialect='excel')\n",
    "#             wr.writerow(['sen','spef','auc'])\n",
    "#             wr.writerow(stats)\n",
    "        \n",
    "       \n",
    "#         with open(f\"master_{task}SVM_CCshap.csv\",\"a\") as sp:\n",
    "#             sp = csv.writer(ir, dialect='excel')\n",
    "#             sp.writerow(['feature','shap_value'])\n",
    "#             sp.writerows([top10])\n",
    "            \n",
    "\n",
    "#         with open(res_output, \"w\") as f:\n",
    "#             f.write(f'''\n",
    "# auc1: {auc_score}\n",
    "# auc2: {auc_score1}\n",
    "# sensitivity: {sen}\n",
    "# specificity: {spe}\n",
    "# J: {th}\n",
    "#             ''')\n",
    "\n",
    "ptIDs = pd.read_csv(\"01_MQ_Incident_Match_Files/matched_case_control_CC_01yr.csv\",usecols=['PATID'],dtype =str)\n",
    "ptIDs.head()\n",
    "fea2id, features = pkl_load(\"./03_MQ_Encoding_Files/data_CC0yr_expr_features.pkl\")\n",
    "data = pkl_load(\"./03_MQ_Encoding_Files/data_CC0yr_expr.pkl\")\n",
    "\n",
    "\n",
    "\n",
    "for i in tqdm(range(5)):\n",
    "    train_id, test_id = train_test_split(ptIDs,test_size=0.2)\n",
    "    test_id.head(), train_id.head(), test_id.shape, train_id.shape\n",
    "    test_ids = test_id.PATID.to_list()\n",
    "    train_ids = train_id.PATID.to_list()\n",
    "\n",
    "    #print(data[0][0])\n",
    "\n",
    "    trains = []\n",
    "    tests = []\n",
    "    count = 0\n",
    "    for dp in data:\n",
    "        pid = dp[0]\n",
    "        ndata = dp[1:]\n",
    "        if pid in train_ids:\n",
    "            trains.append(ndata)\n",
    "        elif pid in test_ids:\n",
    "            tests.append(ndata)\n",
    "        else:\n",
    "            count = count + 1\n",
    "\n",
    "    print(count)\n",
    "    matrix, pids = to_matrix(trains, len(fea2id), -1)\n",
    "\n",
    "    tr_dx, tr_dy = create_data(matrix)\n",
    "\n",
    "    matrix, pids = to_matrix(tests, len(fea2id), -1)\n",
    "\n",
    "    ts_dx, ts_dy = create_data(matrix)\n",
    "\n",
    "\n",
    "    pkl4_dump((tr_dx, tr_dy, ts_dx, ts_dy), \"./03_MQ_Encoding_Files/expr_data_CC0yr_train_test.pkl\")\n",
    "\n",
    "\n",
    "##Algorithm\n",
    "    expr3(clf3, tuned_parameters_max_iter3, tasks = [0], nb = 10, nit = 20, model_name = 'SVM')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(5681, 10046)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(5681, 10045) (5681,)\n",
      "(1421, 10046)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(1421, 10045) (1421,)\n",
      "current task: 0 SVM\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=10)]: Done 100 out of 100 | elapsed: 19.5min finished\n",
      "The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "Solver terminated early (max_iter=90).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [20:53<1:23:35, 1253.93s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score is :  0.5510510079632686\n",
      "0\n",
      "(5681, 10046)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(5681, 10045) (5681,)\n",
      "(1421, 10046)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(1421, 10045) (1421,)\n",
      "current task: 0 SVM\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=10)]: Done 100 out of 100 | elapsed: 19.5min finished\n",
      "The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "Solver terminated early (max_iter=90).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [41:49<1:02:43, 1254.45s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score is :  0.4677378056586864\n",
      "0\n",
      "(5681, 10046)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(5681, 10045) (5681,)\n",
      "(1421, 10046)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(1421, 10045) (1421,)\n",
      "current task: 0 SVM\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-842c0d2c23cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;31m##Algorithm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m     \u001b[0mexpr4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuned_parameters_max_iter4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'SVM'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-842c0d2c23cb>\u001b[0m in \u001b[0;36mexpr4\u001b[0;34m(clf, params, tasks, nb, nit, model_name)\u001b[0m\n\u001b[1;32m     20\u001b[0m                                       \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                                       verbose=1, iid=True, n_iter=nit)\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mcv_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_dx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_dy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mbest_5_cv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mopt_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1513\u001b[0m         evaluate_candidates(ParameterSampler(\n\u001b[1;32m   1514\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1515\u001b[0;31m             random_state=self.random_state))\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    709\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 711\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tuned_parameters_max_iter4 = {\n",
    "    'max_iter': range(50, 100, 10),\n",
    "    'tol': [0.0001, 0.001, 0.01, 0.1],\n",
    "    'C': range(1, 50, 2),\n",
    "    'class_weight': [None, 'balanced']\n",
    "    }\n",
    "\n",
    "clf4 = svm.SVC(probability=True)\n",
    "def expr4(clf, params, tasks, nb, nit, model_name):\n",
    "    for task in tasks:\n",
    "        print(f\"current task: {task} {model_name}\")\n",
    "        res_output = f\"{task}year_{model_name}.txt\"\n",
    "        model_dump = f\"{task}year_{model_name}_model.pkl\"\n",
    "\n",
    "        fea2iD, features = pkl_load(f\"./03_MQ_Encoding_Files/data_CC{task}yr_expr_features.pkl\")\n",
    "        tr_dx, tr_dy, ts_dx, ts_dy = pkl4_load(f\"./03_MQ_Encoding_Files/expr_data_CC{task}yr_train_test.pkl\")\n",
    "        #print(tr_dx.shape, ts_dx.shape)\n",
    "        \n",
    "        cv_model = RandomizedSearchCV(clf, params, scoring='roc_auc', n_jobs=nb, \n",
    "                                      cv=StratifiedKFold(n_splits=5, shuffle=True), \n",
    "                                      verbose=1, iid=True, n_iter=nit)\n",
    "        cv_model.fit(tr_dx, tr_dy)\n",
    "        best_5_cv = cv_model.best_estimator_\n",
    "        opt_clf = cv_model.best_estimator_\n",
    "        pkl_dump(opt_clf, model_dump)\n",
    "\n",
    "        preds = opt_clf.predict_proba(ts_dx)\n",
    "        pkl_dump(preds, f\"{task}year_{model_name}_preds.pkl\")\n",
    "\n",
    "        idx = np.argmax(opt_clf.classes_)\n",
    "        preds_1 = list(map(lambda x: x[idx], preds))\n",
    "\n",
    "        auc_score = roc_auc_score(ts_dy, preds_1)\n",
    "        fprs, tprs, ths = roc_curve(ts_dy, preds_1)\n",
    "        print(\"auc_score is : \",auc_score)\n",
    "        \n",
    "        return auc_score\n",
    "#         J_idx = np.argmax(tprs - fprs)\n",
    "#         fpr, tpr, th = fprs[J_idx], tprs[J_idx], ths[J_idx]\n",
    "#         auc_score1 = auc(fprs, tprs)\n",
    "\n",
    "#         sen = tpr\n",
    "#         spe = 1 - fpr\n",
    "#         stats = [sen, spe, auc_score1]\n",
    "        \n",
    "# change below to shap for SVM\n",
    "\n",
    "#         shap.initjs()\n",
    "#         explainer = shap.TreeExplainer(opt_clf)\n",
    "#         shap_values = explainer.shap_values(tr_dx)\n",
    "#         top10 = shap_values[:10][:]\n",
    "        \n",
    "#         with open(f\"master_{task}SVM_CCstats.csv\", \"a\") as fp:\n",
    "#             wr = csv.writer(fp, dialect='excel')\n",
    "#             wr.writerow(['sen','spef','auc'])\n",
    "#             wr.writerow(stats)\n",
    "        \n",
    "       \n",
    "#         with open(f\"master_{task}SVM_CCshap.csv\",\"a\") as sp:\n",
    "#             sp = csv.writer(ir, dialect='excel')\n",
    "#             sp.writerow(['feature','shap_value'])\n",
    "#             sp.writerows([top10])\n",
    "            \n",
    "\n",
    "#         with open(res_output, \"w\") as f:\n",
    "#             f.write(f'''\n",
    "# auc1: {auc_score}\n",
    "# auc2: {auc_score1}\n",
    "# sensitivity: {sen}\n",
    "# specificity: {spe}\n",
    "# J: {th}\n",
    "#             ''')\n",
    "\n",
    "ptIDs = pd.read_csv(\"01_MQ_Incident_Match_Files/matched_case_control_CC_01yr.csv\",usecols=['PATID'],dtype =str)\n",
    "ptIDs.head()\n",
    "fea2id, features = pkl_load(\"./03_MQ_Encoding_Files/data_CC0yr_expr_features.pkl\")\n",
    "data = pkl_load(\"./03_MQ_Encoding_Files/data_CC0yr_expr.pkl\")\n",
    "\n",
    "\n",
    "\n",
    "for i in tqdm(range(5)):\n",
    "    train_id, test_id = train_test_split(ptIDs,test_size=0.2)\n",
    "    test_id.head(), train_id.head(), test_id.shape, train_id.shape\n",
    "    test_ids = test_id.PATID.to_list()\n",
    "    train_ids = train_id.PATID.to_list()\n",
    "\n",
    "    #print(data[0][0])\n",
    "\n",
    "    trains = []\n",
    "    tests = []\n",
    "    count = 0\n",
    "    for dp in data:\n",
    "        pid = dp[0]\n",
    "        ndata = dp[1:]\n",
    "        if pid in train_ids:\n",
    "            trains.append(ndata)\n",
    "        elif pid in test_ids:\n",
    "            tests.append(ndata)\n",
    "        else:\n",
    "            count = count + 1\n",
    "\n",
    "    print(count)\n",
    "    matrix, pids = to_matrix(trains, len(fea2id), -1)\n",
    "\n",
    "    tr_dx, tr_dy = create_data(matrix)\n",
    "\n",
    "    matrix, pids = to_matrix(tests, len(fea2id), -1)\n",
    "\n",
    "    ts_dx, ts_dy = create_data(matrix)\n",
    "\n",
    "\n",
    "    pkl4_dump((tr_dx, tr_dy, ts_dx, ts_dy), \"./03_MQ_Encoding_Files/expr_data_CC0yr_train_test.pkl\")\n",
    "\n",
    "\n",
    "##Algorithm\n",
    "    expr4(clf4, tuned_parameters_max_iter4, tasks = [0], nb = 10, nit = 20, model_name = 'SVM')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter test - C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(5681, 10046)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(5681, 10045) (5681,)\n",
      "(1421, 10046)\n",
      "[1. 1. 0. ... 0. 0. 0.]\n",
      "(1421, 10045) (1421,)\n",
      "current task: 0 SVM\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed: 31.0min\n",
      "[Parallel(n_jobs=10)]: Done 100 out of 100 | elapsed: 75.3min finished\n",
      "The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "Solver terminated early (max_iter=900).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [1:21:51<5:27:25, 4911.29s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score is :  0.7061149628627549\n",
      "0\n",
      "(5681, 10046)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(5681, 10045) (5681,)\n",
      "(1421, 10046)\n",
      "[1. 0. 0. ... 0. 0. 0.]\n",
      "(1421, 10045) (1421,)\n",
      "current task: 0 SVM\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed: 30.9min\n",
      "[Parallel(n_jobs=10)]: Done 100 out of 100 | elapsed: 75.6min finished\n",
      "The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "Solver terminated early (max_iter=900).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [2:43:57<4:05:46, 4915.62s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score is :  0.6869854753290334\n",
      "0\n",
      "(5681, 10046)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(5681, 10045) (5681,)\n",
      "(1421, 10046)\n",
      "[1. 0. 0. ... 0. 0. 0.]\n",
      "(1421, 10045) (1421,)\n",
      "current task: 0 SVM\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed: 32.4min\n",
      "[Parallel(n_jobs=10)]: Done 100 out of 100 | elapsed: 77.5min finished\n",
      "The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "Solver terminated early (max_iter=900).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [4:08:08<2:45:12, 4956.47s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score is :  0.6869854753290334\n",
      "0\n",
      "(5681, 10046)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(5681, 10045) (5681,)\n",
      "(1421, 10046)\n",
      "[1. 0. 0. ... 0. 0. 0.]\n",
      "(1421, 10045) (1421,)\n",
      "current task: 0 SVM\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed: 31.9min\n",
      "[Parallel(n_jobs=10)]: Done 100 out of 100 | elapsed: 77.5min finished\n",
      "The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "Solver terminated early (max_iter=900).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 80%|████████  | 4/5 [5:33:26<1:23:24, 5004.71s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score is :  0.6869854753290334\n",
      "0\n",
      "(5681, 10046)\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(5681, 10045) (5681,)\n",
      "(1421, 10046)\n",
      "[1. 0. 0. ... 0. 0. 0.]\n",
      "(1421, 10045) (1421,)\n",
      "current task: 0 SVM\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed: 33.5min\n",
      "[Parallel(n_jobs=10)]: Done 100 out of 100 | elapsed: 76.7min finished\n",
      "The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "Solver terminated early (max_iter=900).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [6:56:37<00:00, 5000.65s/it]  \u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score is :  0.6869854753290334\n"
     ]
    }
   ],
   "source": [
    "tuned_parameters_c1 = {\n",
    "    'max_iter': range(100, 500, 50),\n",
    "    'tol': [0.0001, 0.001, 0.01, 0.1],\n",
    "    #'C': range(1, 50, 2),\n",
    "    'class_weight': [None, 'balanced']\n",
    "    }\n",
    "\n",
    "clf1 = svm.SVC(probability=True)\n",
    "def expr1(clf, params, tasks, nb, nit, model_name):\n",
    "    for task in tasks:\n",
    "        print(f\"current task: {task} {model_name}\")\n",
    "        res_output = f\"{task}year_{model_name}.txt\"\n",
    "        model_dump = f\"{task}year_{model_name}_model.pkl\"\n",
    "\n",
    "        fea2iD, features = pkl_load(f\"./03_MQ_Encoding_Files/data_CC{task}yr_expr_features.pkl\")\n",
    "        tr_dx, tr_dy, ts_dx, ts_dy = pkl4_load(f\"./03_MQ_Encoding_Files/expr_data_CC{task}yr_train_test.pkl\")\n",
    "        #print(tr_dx.shape, ts_dx.shape)\n",
    "        \n",
    "        cv_model = RandomizedSearchCV(clf, params, scoring='roc_auc', n_jobs=nb, \n",
    "                                      cv=StratifiedKFold(n_splits=5, shuffle=True), \n",
    "                                      verbose=1, iid=True, n_iter=nit)\n",
    "        cv_model.fit(tr_dx, tr_dy)\n",
    "        best_5_cv = cv_model.best_estimator_\n",
    "        opt_clf = cv_model.best_estimator_\n",
    "        pkl_dump(opt_clf, model_dump)\n",
    "\n",
    "        preds = opt_clf.predict_proba(ts_dx)\n",
    "        pkl_dump(preds, f\"{task}year_{model_name}_preds.pkl\")\n",
    "\n",
    "        idx = np.argmax(opt_clf.classes_)\n",
    "        preds_1 = list(map(lambda x: x[idx], preds))\n",
    "\n",
    "        auc_score = roc_auc_score(ts_dy, preds_1)\n",
    "        fprs, tprs, ths = roc_curve(ts_dy, preds_1)\n",
    "        print(\"auc_score is : \",auc_score)\n",
    "        \n",
    "        return auc_score\n",
    "#         J_idx = np.argmax(tprs - fprs)\n",
    "#         fpr, tpr, th = fprs[J_idx], tprs[J_idx], ths[J_idx]\n",
    "#         auc_score1 = auc(fprs, tprs)\n",
    "\n",
    "#         sen = tpr\n",
    "#         spe = 1 - fpr\n",
    "#         stats = [sen, spe, auc_score1]\n",
    "        \n",
    "# change below to shap for SVM\n",
    "\n",
    "#         shap.initjs()\n",
    "#         explainer = shap.TreeExplainer(opt_clf)\n",
    "#         shap_values = explainer.shap_values(tr_dx)\n",
    "#         top10 = shap_values[:10][:]\n",
    "        \n",
    "#         with open(f\"master_{task}SVM_CCstats.csv\", \"a\") as fp:\n",
    "#             wr = csv.writer(fp, dialect='excel')\n",
    "#             wr.writerow(['sen','spef','auc'])\n",
    "#             wr.writerow(stats)\n",
    "        \n",
    "       \n",
    "#         with open(f\"master_{task}SVM_CCshap.csv\",\"a\") as sp:\n",
    "#             sp = csv.writer(ir, dialect='excel')\n",
    "#             sp.writerow(['feature','shap_value'])\n",
    "#             sp.writerows([top10])\n",
    "            \n",
    "\n",
    "#         with open(res_output, \"w\") as f:\n",
    "#             f.write(f'''\n",
    "# auc1: {auc_score}\n",
    "# auc2: {auc_score1}\n",
    "# sensitivity: {sen}\n",
    "# specificity: {spe}\n",
    "# J: {th}\n",
    "#             ''')\n",
    "\n",
    "ptIDs = pd.read_csv(\"01_MQ_Incident_Match_Files/matched_case_control_CC_01yr.csv\",usecols=['PATID'],dtype =str)\n",
    "ptIDs.head()\n",
    "fea2id, features = pkl_load(\"./03_MQ_Encoding_Files/data_CC0yr_expr_features.pkl\")\n",
    "data = pkl_load(\"./03_MQ_Encoding_Files/data_CC0yr_expr.pkl\")\n",
    "\n",
    "\n",
    "\n",
    "for i in tqdm(range(5)):\n",
    "    train_id, test_id = train_test_split(ptIDs,test_size=0.2)\n",
    "    test_id.head(), train_id.head(), test_id.shape, train_id.shape\n",
    "    test_ids = test_id.PATID.to_list()\n",
    "    train_ids = train_id.PATID.to_list()\n",
    "\n",
    "    #print(data[0][0])\n",
    "\n",
    "    trains = []\n",
    "    tests = []\n",
    "    count = 0\n",
    "    for dp in data:\n",
    "        pid = dp[0]\n",
    "        ndata = dp[1:]\n",
    "        if pid in train_ids:\n",
    "            trains.append(ndata)\n",
    "        elif pid in test_ids:\n",
    "            tests.append(ndata)\n",
    "        else:\n",
    "            count = count + 1\n",
    "\n",
    "    print(count)\n",
    "    matrix, pids = to_matrix(trains, len(fea2id), -1)\n",
    "\n",
    "    tr_dx, tr_dy = create_data(matrix)\n",
    "\n",
    "    matrix, pids = to_matrix(tests, len(fea2id), -1)\n",
    "\n",
    "    ts_dx, ts_dy = create_data(matrix)\n",
    "\n",
    "\n",
    "    pkl4_dump((tr_dx, tr_dy, ts_dx, ts_dy), \"./03_MQ_Encoding_Files/expr_data_CC0yr_train_test.pkl\")\n",
    "\n",
    "\n",
    "##Algorithm\n",
    "    expr1(clf1, tuned_parameters_c1, tasks = [0], nb = 10, nit = 20, model_name = 'SVM')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MyPython3",
   "language": "python",
   "name": "mypython3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
